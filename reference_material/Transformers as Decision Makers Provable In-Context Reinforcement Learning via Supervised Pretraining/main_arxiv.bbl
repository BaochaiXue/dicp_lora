\begin{thebibliography}{81}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2019)Agarwal, Jiang, Kakade, and
  Sun]{agarwal2019reinforcement}
Alekh Agarwal, Nan Jiang, Sham~M Kakade, and Wen Sun.
\newblock Reinforcement learning: Theory and algorithms.
\newblock \emph{CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep}, 32, 2019.

\bibitem[Ahn et~al.(2023)Ahn, Cheng, Daneshmand, and Sra]{ahn2023transformers}
Kwangjun Ahn, Xiang Cheng, Hadi Daneshmand, and Suvrit Sra.
\newblock Transformers learn to implement preconditioned gradient descent for
  in-context learning.
\newblock \emph{arXiv preprint arXiv:2306.00297}, 2023.

\bibitem[Aky{\"u}rek et~al.(2022)Aky{\"u}rek, Schuurmans, Andreas, Ma, and
  Zhou]{akyurek2022learning}
Ekin Aky{\"u}rek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou.
\newblock What learning algorithm is in-context learning? investigations with
  linear models.
\newblock \emph{arXiv preprint arXiv:2211.15661}, 2022.

\bibitem[Azar et~al.(2017)Azar, Osband, and Munos]{azar2017minimax}
Mohammad~Gheshlaghi Azar, Ian Osband, and R{\'e}mi Munos.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  263--272. PMLR, 2017.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bai et~al.(2023)Bai, Chen, Wang, Xiong, and Mei]{bai2023transformers}
Yu~Bai, Fan Chen, Huan Wang, Caiming Xiong, and Song Mei.
\newblock Transformers as statisticians: Provable in-context learning with
  in-context algorithm selection.
\newblock \emph{arXiv preprint arXiv:2306.04637}, 2023.

\bibitem[Bengio et~al.(1990)Bengio, Bengio, and Cloutier]{bengio1990learning}
Yoshua Bengio, Samy Bengio, and Jocelyn Cloutier.
\newblock \emph{Learning a synaptic learning rule}.
\newblock Citeseer, 1990.

\bibitem[Bhattamishra et~al.(2020)Bhattamishra, Patel, and
  Goyal]{bhattamishra2020computational}
Satwik Bhattamishra, Arkil Patel, and Navin Goyal.
\newblock On the computational power of transformers and its implications in
  sequence modeling.
\newblock \emph{arXiv preprint arXiv:2006.09286}, 2020.

\bibitem[Brandfonbrener et~al.(2022)Brandfonbrener, Bietti, Buckman, Laroche,
  and Bruna]{brandfonbrener2022does}
David Brandfonbrener, Alberto Bietti, Jacob Buckman, Romain Laroche, and Joan
  Bruna.
\newblock When does return-conditioned supervised learning work for offline
  reinforcement learning?
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 1542--1553, 2022.

\bibitem[Brohan et~al.(2022)Brohan, Brown, Carbajal, Chebotar, Dabis, Finn,
  Gopalakrishnan, Hausman, Herzog, Hsu, et~al.]{brohan2022rt}
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis,
  Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine
  Hsu, et~al.
\newblock Rt-1: Robotics transformer for real-world control at scale.
\newblock \emph{arXiv preprint arXiv:2212.06817}, 2022.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel,
  Srinivas, and Mordatch]{chen2021decision}
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha
  Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 15084--15097, 2021.

\bibitem[Chu et~al.(2011)Chu, Li, Reyzin, and Schapire]{chu2011contextual}
Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire.
\newblock Contextual bandits with linear payoff functions.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 208--214. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dorfman et~al.(2021)Dorfman, Shenfeld, and Tamar]{dorfman2021offline}
Ron Dorfman, Idan Shenfeld, and Aviv Tamar.
\newblock Offline meta reinforcement learning--identifiability challenges and
  effective data collection strategies.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 4607--4618, 2021.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{duan2016rl}
Yan Duan, John Schulman, Xi~Chen, Peter~L Bartlett, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Rl$^2$: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International conference on machine learning}, pages
  1126--1135. PMLR, 2017.

\bibitem[Foster et~al.(2021)Foster, Kakade, Qian, and
  Rakhlin]{foster2021statistical}
Dylan~J Foster, Sham~M Kakade, Jian Qian, and Alexander Rakhlin.
\newblock The statistical complexity of interactive decision making.
\newblock \emph{arXiv preprint arXiv:2112.13487}, 2021.

\bibitem[Fu et~al.(2023)Fu, Guo, Bai, and Mei]{fu2023can}
Hengyu Fu, Tianyu Guo, Yu~Bai, and Song Mei.
\newblock What can a single attention layer learn? a study through the random
  features lens.
\newblock \emph{arXiv preprint arXiv:2307.11353}, 2023.

\bibitem[Fu et~al.(2016)Fu, Levine, and Abbeel]{fu2016one}
Justin Fu, Sergey Levine, and Pieter Abbeel.
\newblock One-shot learning of manipulation skills with online dynamics
  adaptation and neural network priors.
\newblock In \emph{2016 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 4019--4026. IEEE, 2016.

\bibitem[Garg et~al.(2022)Garg, Tsipras, Liang, and Valiant]{garg2022can}
Shivam Garg, Dimitris Tsipras, Percy~S Liang, and Gregory Valiant.
\newblock What can transformers learn in-context? a case study of simple
  function classes.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 30583--30598, 2022.

\bibitem[Geer(2000)]{geer2000empirical}
Sara~A Geer.
\newblock \emph{Empirical Processes in M-estimation}, volume~6.
\newblock Cambridge university press, 2000.

\bibitem[Gupta et~al.(2018)Gupta, Mendonca, Liu, Abbeel, and
  Levine]{gupta2018meta}
Abhishek Gupta, Russell Mendonca, YuXuan Liu, Pieter Abbeel, and Sergey Levine.
\newblock Meta-reinforcement learning of structured exploration strategies.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Hochreiter et~al.(2001)Hochreiter, Younger, and
  Conwell]{hochreiter2001learning}
Sepp Hochreiter, A~Steven Younger, and Peter~R Conwell.
\newblock Learning to learn using gradient descent.
\newblock In \emph{Artificial Neural Networksâ€”ICANN 2001: International
  Conference Vienna, Austria, August 21--25, 2001 Proceedings 11}, pages
  87--94. Springer, 2001.

\bibitem[Hron et~al.(2020)Hron, Bahri, Sohl-Dickstein, and
  Novak]{hron2020infinite}
Jiri Hron, Yasaman Bahri, Jascha Sohl-Dickstein, and Roman Novak.
\newblock Infinite attention: Nngp and ntk for deep attention networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  4376--4386. PMLR, 2020.

\bibitem[Humplik et~al.(2019)Humplik, Galashov, Hasenclever, Ortega, Teh, and
  Heess]{humplik2019meta}
Jan Humplik, Alexandre Galashov, Leonard Hasenclever, Pedro~A Ortega, Yee~Whye
  Teh, and Nicolas Heess.
\newblock Meta reinforcement learning as task inference.
\newblock \emph{arXiv preprint arXiv:1905.06424}, 2019.

\bibitem[Ishii et~al.(2002)Ishii, Yoshida, and Yoshimoto]{ishii2002control}
Shin Ishii, Wako Yoshida, and Junichiro Yoshimoto.
\newblock Control of exploitation--exploration meta-parameter in reinforcement
  learning.
\newblock \emph{Neural networks}, 15\penalty0 (4-6):\penalty0 665--687, 2002.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{janner2021offline}
Michael Janner, Qiyang Li, and Sergey Levine.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 1273--1286, 2021.

\bibitem[Laskin et~al.(2022)Laskin, Wang, Oh, Parisotto, Spencer, Steigerwald,
  Strouse, Hansen, Filos, Brooks, et~al.]{laskin2022context}
Michael Laskin, Luyu Wang, Junhyuk Oh, Emilio Parisotto, Stephen Spencer,
  Richie Steigerwald, DJ~Strouse, Steven Hansen, Angelos Filos, Ethan Brooks,
  et~al.
\newblock In-context reinforcement learning with algorithm distillation.
\newblock \emph{arXiv preprint arXiv:2210.14215}, 2022.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Laurent and Massart(2000)]{laurent2000adaptive}
Beatrice Laurent and Pascal Massart.
\newblock Adaptive estimation of a quadratic functional by model selection.
\newblock \emph{Annals of statistics}, pages 1302--1338, 2000.

\bibitem[Lee et~al.(2023)Lee, Xie, Pacchiano, Chandak, Finn, Nachum, and
  Brunskill]{lee2023supervised}
Jonathan~N Lee, Annie Xie, Aldo Pacchiano, Yash Chandak, Chelsea Finn, Ofir
  Nachum, and Emma Brunskill.
\newblock Supervised pretraining can learn in-context reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2306.14892}, 2023.

\bibitem[Lee et~al.(2022)Lee, Nachum, Yang, Lee, Freeman, Guadarrama, Fischer,
  Xu, Jang, Michalewski, et~al.]{lee2022multi}
Kuang-Huei Lee, Ofir Nachum, Mengjiao~Sherry Yang, Lisa Lee, Daniel Freeman,
  Sergio Guadarrama, Ian Fischer, Winnie Xu, Eric Jang, Henryk Michalewski,
  et~al.
\newblock Multi-game decision transformers.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 27921--27936, 2022.

\bibitem[Li et~al.(2020)Li, Yang, and Luo]{li2020focal}
Lanqing Li, Rui Yang, and Dijun Luo.
\newblock Focal: Efficient fully-offline meta-reinforcement learning via
  distance metric learning and behavior regularization.
\newblock \emph{arXiv preprint arXiv:2010.01112}, 2020.

\bibitem[Li et~al.(2023)Li, Ildiz, Papailiopoulos, and
  Oymak]{li2023transformers}
Yingcong Li, M~Emrullah Ildiz, Dimitris Papailiopoulos, and Samet Oymak.
\newblock Transformers as algorithms: Generalization and implicit model
  selection in in-context learning.
\newblock \emph{arXiv preprint arXiv:2301.07067}, 2023.

\bibitem[Liu et~al.(2022)Liu, Ash, Goel, Krishnamurthy, and
  Zhang]{liu2022transformers}
Bingbin Liu, Jordan~T Ash, Surbhi Goel, Akshay Krishnamurthy, and Cyril Zhang.
\newblock Transformers learn shortcuts to automata.
\newblock \emph{arXiv preprint arXiv:2210.10749}, 2022.

\bibitem[Lu(1998)]{lu1998pade}
Ya~Yan Lu.
\newblock A pad{\'e} approximation method for square roots of symmetric
  positive definite matrices.
\newblock \emph{SIAM journal on matrix analysis and applications}, 19\penalty0
  (3):\penalty0 833--845, 1998.

\bibitem[Mei and Wu(2023)]{mei2023deep}
Song Mei and Yuchen Wu.
\newblock Deep networks as denoising algorithms: Sample-efficient learning of
  diffusion models in high-dimensional graphical models.
\newblock \emph{arXiv preprint arXiv:2309.11420}, 2023.

\bibitem[Mitchell et~al.(2021)Mitchell, Rafailov, Peng, Levine, and
  Finn]{mitchell2021offline}
Eric Mitchell, Rafael Rafailov, Xue~Bin Peng, Sergey Levine, and Chelsea Finn.
\newblock Offline meta-reinforcement learning with advantage weighting.
\newblock In \emph{International Conference on Machine Learning}, pages
  7780--7791. PMLR, 2021.

\bibitem[Nagabandi et~al.(2018)Nagabandi, Clavera, Liu, Fearing, Abbeel,
  Levine, and Finn]{nagabandi2018learning}
Anusha Nagabandi, Ignasi Clavera, Simin Liu, Ronald~S Fearing, Pieter Abbeel,
  Sergey Levine, and Chelsea Finn.
\newblock Learning to adapt in dynamic, real-world environments through
  meta-reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1803.11347}, 2018.

\bibitem[Naik and Mammone(1992)]{naik1992meta}
Devang~K Naik and Richard~J Mammone.
\newblock Meta-neural networks that learn by learning.
\newblock In \emph{[Proceedings 1992] IJCNN International Joint Conference on
  Neural Networks}, volume~1, pages 437--442. IEEE, 1992.

\bibitem[Nesterov(2003)]{nesterov2003introductory}
Yurii Nesterov.
\newblock \emph{Introductory lectures on convex optimization: A basic course},
  volume~87.
\newblock Springer Science \& Business Media, 2003.

\bibitem[Nichol et~al.(2018)Nichol, Achiam, and Schulman]{nichol2018first}
Alex Nichol, Joshua Achiam, and John Schulman.
\newblock On first-order meta-learning algorithms.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[OpenAI(2023)]{openai2023gpt}
OpenAI.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Paster et~al.(2022)Paster, McIlraith, and Ba]{paster2022you}
Keiran Paster, Sheila McIlraith, and Jimmy Ba.
\newblock You canâ€™t count on luck: Why decision transformers and rvs fail in
  stochastic environments.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 38966--38979, 2022.

\bibitem[P{\'e}rez et~al.(2019)P{\'e}rez, Marinkovi{\'c}, and
  Barcel{\'o}]{perez2019turing}
Jorge P{\'e}rez, Javier Marinkovi{\'c}, and Pablo Barcel{\'o}.
\newblock On the turing completeness of modern neural network architectures.
\newblock \emph{arXiv preprint arXiv:1901.03429}, 2019.

\bibitem[Pong et~al.(2022)Pong, Nair, Smith, Huang, and
  Levine]{pong2022offline}
Vitchyr~H Pong, Ashvin~V Nair, Laura~M Smith, Catherine Huang, and Sergey
  Levine.
\newblock Offline meta-reinforcement learning with online self-supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  17811--17829. PMLR, 2022.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
  Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Rajaraman et~al.(2020)Rajaraman, Yang, Jiao, and
  Ramchandran]{rajaraman2020toward}
Nived Rajaraman, Lin Yang, Jiantao Jiao, and Kannan Ramchandran.
\newblock Toward the fundamental limits of imitation learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 2914--2924, 2020.

\bibitem[Rajaraman et~al.(2021)Rajaraman, Han, Yang, Ramchandran, and
  Jiao]{rajaraman2021provably}
Nived Rajaraman, Yanjun Han, Lin~F Yang, Kannan Ramchandran, and Jiantao Jiao.
\newblock Provably breaking the quadratic error compounding barrier in
  imitation learning, optimally.
\newblock \emph{arXiv preprint arXiv:2102.12948}, 2021.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Finn, Levine, and
  Quillen]{rakelly2019efficient}
Kate Rakelly, Aurick Zhou, Chelsea Finn, Sergey Levine, and Deirdre Quillen.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock In \emph{International conference on machine learning}, pages
  5331--5340. PMLR, 2019.

\bibitem[Rashidinejad et~al.(2021)Rashidinejad, Zhu, Ma, Jiao, and
  Russell]{rashidinejad2021bridging}
Paria Rashidinejad, Banghua Zhu, Cong Ma, Jiantao Jiao, and Stuart Russell.
\newblock Bridging offline reinforcement learning and imitation learning: A
  tale of pessimism.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11702--11716, 2021.

\bibitem[Ravent{\'o}s et~al.(2023)Ravent{\'o}s, Paul, Chen, and
  Ganguli]{raventos2023pretraining}
Allan Ravent{\'o}s, Mansheej Paul, Feng Chen, and Surya Ganguli.
\newblock Pretraining task diversity and the emergence of non-bayesian
  in-context learning for regression.
\newblock \emph{arXiv preprint arXiv:2306.15063}, 2023.

\bibitem[Reed et~al.(2022)Reed, Zolna, Parisotto, Colmenarejo, Novikov,
  Barth-Maron, Gimenez, Sulsky, Kay, Springenberg, et~al.]{reed2022generalist}
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio~Gomez Colmenarejo, Alexander
  Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay,
  Jost~Tobias Springenberg, et~al.
\newblock A generalist agent.
\newblock \emph{arXiv preprint arXiv:2205.06175}, 2022.

\bibitem[Ross and Bagnell(2010)]{ross2010efficient}
St{\'e}phane Ross and Drew Bagnell.
\newblock Efficient reductions for imitation learning.
\newblock In \emph{Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 661--668. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem[Ross et~al.(2011)Ross, Gordon, and Bagnell]{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In \emph{Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 627--635. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem[Rothfuss et~al.(2018)Rothfuss, Lee, Clavera, Asfour, and
  Abbeel]{rothfuss2018promp}
Jonas Rothfuss, Dennis Lee, Ignasi Clavera, Tamim Asfour, and Pieter Abbeel.
\newblock Promp: Proximal meta-policy search.
\newblock \emph{arXiv preprint arXiv:1810.06784}, 2018.

\bibitem[Russo et~al.(2018)Russo, Van~Roy, Kazerouni, Osband, Wen,
  et~al.]{russo2018tutorial}
Daniel~J Russo, Benjamin Van~Roy, Abbas Kazerouni, Ian Osband, Zheng Wen,
  et~al.
\newblock A tutorial on thompson sampling.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  11\penalty0 (1):\penalty0 1--96, 2018.

\bibitem[Schaul and Schmidhuber(2010)]{schaul2010metalearning}
Tom Schaul and J{\"u}rgen Schmidhuber.
\newblock Metalearning.
\newblock \emph{Scholarpedia}, 5\penalty0 (6):\penalty0 4650, 2010.

\bibitem[Schmidhuber(1987)]{schmidhuber1987evolutionary}
J{\"u}rgen Schmidhuber.
\newblock \emph{Evolutionary principles in self-referential learning, or on
  learning how to learn: the meta-meta-... hook}.
\newblock PhD thesis, Technische Universit{\"a}t M{\"u}nchen, 1987.

\bibitem[Schmidhuber(1992)]{schmidhuber1992learning}
J{\"u}rgen Schmidhuber.
\newblock Learning to control fast-weight memories: An alternative to dynamic
  recurrent networks.
\newblock \emph{Neural Computation}, 4\penalty0 (1):\penalty0 131--139, 1992.

\bibitem[Shafiullah et~al.(2022)Shafiullah, Cui, Altanzaya, and
  Pinto]{shafiullah2022behavior}
Nur~Muhammad Shafiullah, Zichen Cui, Ariuntuya~Arty Altanzaya, and Lerrel
  Pinto.
\newblock Behavior transformers: Cloning $ k $ modes with one stone.
\newblock \emph{Advances in neural information processing systems},
  35:\penalty0 22955--22968, 2022.

\bibitem[Shen et~al.(2023)Shen, Guo, Tan, Tang, Wang, and Bian]{shen2023study}
Kai Shen, Junliang Guo, Xu~Tan, Siliang Tang, Rui Wang, and Jiang Bian.
\newblock A study on relu and softmax in transformer.
\newblock \emph{arXiv preprint arXiv:2302.06461}, 2023.

\bibitem[Strupl et~al.(2022)Strupl, Faccio, Ashley, Schmidhuber, and
  Srivastava]{vstrupl2022upside}
Miroslav Strupl, Francesco Faccio, Dylan~R Ashley, J{\"u}rgen Schmidhuber, and
  Rupesh~Kumar Srivastava.
\newblock Upside-down reinforcement learning can diverge in stochastic
  environments with episodic resets.
\newblock \emph{arXiv preprint arXiv:2205.06595}, 2022.

\bibitem[Thrun and Pratt(2012)]{thrun2012learning}
Sebastian Thrun and Lorien Pratt.
\newblock \emph{Learning to learn}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Von~Oswald et~al.(2023)Von~Oswald, Niklasson, Randazzo, Sacramento,
  Mordvintsev, Zhmoginov, and Vladymyrov]{von2023transformers}
Johannes Von~Oswald, Eyvind Niklasson, Ettore Randazzo, Jo{\~a}o Sacramento,
  Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov.
\newblock Transformers learn in-context by gradient descent.
\newblock In \emph{International Conference on Machine Learning}, pages
  35151--35174. PMLR, 2023.

\bibitem[Wainwright(2019)]{wainwright2019high}
Martin~J Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge University Press, 2019.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos,
  Blundell, Kumaran, and Botvinick]{wang2016learning}
Jane~X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel~Z Leibo,
  Remi Munos, Charles Blundell, Dharshan Kumaran, and Matt Botvinick.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv preprint arXiv:1611.05763}, 2016.

\bibitem[Wang et~al.(2020)Wang, Cai, Yang, and Wang]{wang2020global}
Lingxiao Wang, Qi~Cai, Zhuoran Yang, and Zhaoran Wang.
\newblock On the global optimality of model-agnostic meta-learning.
\newblock In \emph{International conference on machine learning}, pages
  9837--9846. PMLR, 2020.

\bibitem[Wei et~al.(2022)Wei, Chen, and Ma]{wei2022statistically}
Colin Wei, Yining Chen, and Tengyu Ma.
\newblock Statistically meaningful approximation: a case study on approximating
  turing machines with transformers.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 12071--12083, 2022.

\bibitem[Wortsman et~al.(2023)Wortsman, Lee, Gilmer, and
  Kornblith]{wortsman2023replacing}
Mitchell Wortsman, Jaehoon Lee, Justin Gilmer, and Simon Kornblith.
\newblock Replacing softmax with relu in vision transformers.
\newblock \emph{arXiv preprint arXiv:2309.08586}, 2023.

\bibitem[Xie et~al.(2021)Xie, Raghunathan, Liang, and Ma]{xie2021explanation}
Sang~Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma.
\newblock An explanation of in-context learning as implicit bayesian inference.
\newblock \emph{arXiv preprint arXiv:2111.02080}, 2021.

\bibitem[Yang et~al.(2022)Yang, Schuurmans, Abbeel, and
  Nachum]{yang2022dichotomy}
Mengjiao Yang, Dale Schuurmans, Pieter Abbeel, and Ofir Nachum.
\newblock Dichotomy of control: Separating what you can control from what you
  cannot.
\newblock \emph{arXiv preprint arXiv:2210.13435}, 2022.

\bibitem[Yang et~al.(2023)Yang, Nachum, Du, Wei, Abbeel, and
  Schuurmans]{yang2023foundation}
Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, Pieter Abbeel, and Dale
  Schuurmans.
\newblock Foundation models for decision making: Problems, methods, and
  opportunities.
\newblock \emph{arXiv preprint arXiv:2303.04129}, 2023.

\bibitem[Yao et~al.(2021)Yao, Peng, Papadimitriou, and Narasimhan]{yao2021self}
Shunyu Yao, Binghui Peng, Christos Papadimitriou, and Karthik Narasimhan.
\newblock Self-attention networks can process bounded hierarchical languages.
\newblock \emph{arXiv preprint arXiv:2105.11115}, 2021.

\bibitem[Yun et~al.(2019)Yun, Bhojanapalli, Rawat, Reddi, and
  Kumar]{yun2019transformers}
Chulhee Yun, Srinadh Bhojanapalli, Ankit~Singh Rawat, Sashank~J Reddi, and
  Sanjiv Kumar.
\newblock Are transformers universal approximators of sequence-to-sequence
  functions?
\newblock \emph{arXiv preprint arXiv:1912.10077}, 2019.

\bibitem[Zhang et~al.(2023)Zhang, Frei, and Bartlett]{zhang2023trained}
Ruiqi Zhang, Spencer Frei, and Peter~L Bartlett.
\newblock Trained transformers learn linear models in-context.
\newblock \emph{arXiv preprint arXiv:2306.09927}, 2023.

\bibitem[Zhang et~al.(2022)Zhang, Backurs, Bubeck, Eldan, Gunasekar, and
  Wagner]{zhang2022unveiling}
Yi~Zhang, Arturs Backurs, S{\'e}bastien Bubeck, Ronen Eldan, Suriya Gunasekar,
  and Tal Wagner.
\newblock Unveiling transformers with lego: a synthetic reasoning task.
\newblock \emph{arXiv preprint arXiv:2206.04301}, 2022.

\bibitem[Zintgraf et~al.(2019)Zintgraf, Shiarlis, Igl, Schulze, Gal, Hofmann,
  and Whiteson]{zintgraf2019varibad}
Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze, Yarin
  Gal, Katja Hofmann, and Shimon Whiteson.
\newblock Varibad: A very good method for bayes-adaptive deep rl via
  meta-learning.
\newblock \emph{arXiv preprint arXiv:1910.08348}, 2019.

\end{thebibliography}
